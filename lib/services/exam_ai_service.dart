import 'dart:convert';
import 'package:http/http.dart' as http;
import 'package:kresai/config/api_config.dart';
import 'package:kresai/models/exam.dart';
import 'package:kresai/models/exam_submission.dart';
import 'package:kresai/models/exam_report.dart';
import 'package:kresai/services/exam_ai_prompts.dart';
import 'package:kresai/services/image_generation_service.dart';
import 'package:kresai/app.dart';

/// Exam version generated by AI
class ExamVersion {
  final String versionId;
  final String title;
  final int estimatedMinutes;
  final int questionCount;
  final List<String> formatMix;
  final List<String> instructions;
  final List<ExamQuestion> questions;
  final Map<String, dynamic> scoring;
  final Map<String, dynamic> teacherNotes;

  const ExamVersion({
    required this.versionId,
    required this.title,
    required this.estimatedMinutes,
    required this.questionCount,
    required this.formatMix,
    required this.instructions,
    required this.questions,
    required this.scoring,
    required this.teacherNotes,
  });

  factory ExamVersion.fromJson(Map<String, dynamic> json) {
    return ExamVersion(
      versionId: json['versionId'] as String,
      title: json['title'] as String,
      estimatedMinutes: json['estimatedMinutes'] as int,
      questionCount: json['questionCount'] as int,
      formatMix: (json['formatMix'] as List).cast<String>(),
      instructions: (json['instructions'] as List).cast<String>(),
      questions: (json['questions'] as List)
          .map((e) => ExamQuestion.fromJson(e as Map<String, dynamic>))
          .toList(),
      scoring: json['scoring'] as Map<String, dynamic>,
      teacherNotes: json['teacherNotes'] as Map<String, dynamic>,
    );
  }
}

/// Exam generation result
class ExamGenerationResult {
  final List<ExamVersion> versions; // minimum 3
  final String summaryForTeacher;
  final Map<String, bool> checks;

  ExamGenerationResult({
    required this.versions,
    required this.summaryForTeacher,
    required this.checks,
  });

  factory ExamGenerationResult.fromJson(Map<String, dynamic> json) {
    return ExamGenerationResult(
      versions: (json['versions'] as List)
          .map((e) => ExamVersion.fromJson(e as Map<String, dynamic>))
          .toList(),
      summaryForTeacher: json['summaryForTeacher'] as String,
      checks: Map<String, bool>.from(json['checks'] as Map),
    );
  }
}

/// Exam AI Service - Gemini integration for exam generation and grading
class ExamAIService {
  static const String _baseUrl = 'https://generativelanguage.googleapis.com/v1beta/models'; // Changed v1 to v1beta
  static const String _model = 'gemini-2.0-flash:generateContent';

  final String _apiKey;
  final ImageGenerationService _imageService;

  ExamAIService() 
    : _apiKey = ApiConfig.geminiApiKey,
      _imageService = ImageGenerationService();

  /// A) Generate exam options (min 3 versions)
  Future<ExamGenerationResult> generateExam({
    required String gradeBand,
    required String timeWindow,
    required List<String> topics,
    required int questionCount,
    required int durationMinutes,
    required String difficulty,
    required String teacherStyle,
    required List<String> formatsAllowed,
  }) async {
    final prompt = ExamAIPrompts.buildExamGenerationPrompt(
      gradeBand: gradeBand,
      timeWindow: timeWindow,
      topics: topics,
      questionCount: questionCount,
      durationMinutes: durationMinutes,
      difficulty: difficulty,
      teacherStyle: teacherStyle,
      formatsAllowed: formatsAllowed,
    );

    final response = await _callGemini(prompt);
    final result = ExamGenerationResult.fromJson(response);
    
    // Generate images for picture choice questions
    final updatedVersions = <ExamVersion>[];
    
    for (var version in result.versions) {
      final updatedQuestions = <ExamQuestion>[];
      
      for (var question in version.questions) {
        if (question.type == QuestionType.pictureChoice && 
            question.choices != null && 
            question.choices!.isNotEmpty) {
          try {
            final imageUrls = await _imageService.generateImagesForChoices(question.choices!);
            if (imageUrls.isNotEmpty) {
              // Create new question with generated image URLs
              updatedQuestions.add(ExamQuestion(
                qid: question.qid,
                type: question.type,
                prompt: question.prompt,
                choices: question.choices,
                choiceImageUrls: imageUrls,
                matchingPairs: question.matchingPairs,
                correctAnswer: question.correctAnswer,
                imageUrl: question.imageUrl,
                audioUrl: question.audioUrl,
                points: question.points,
                rubric: question.rubric,
              ));
            } else {
              updatedQuestions.add(question);
            }
          } catch (e) {
            print('Warning: Failed to generate images for question ${question.qid}: $e');
            updatedQuestions.add(question);
          }
        } else {
          updatedQuestions.add(question);
        }
      }
      
      // Create new version with updated questions
      updatedVersions.add(ExamVersion(
        versionId: version.versionId,
        title: version.title,
        estimatedMinutes: version.estimatedMinutes,
        questionCount: version.questionCount,
        formatMix: version.formatMix,
        instructions: version.instructions,
        questions: updatedQuestions,
        scoring: version.scoring,
        teacherNotes: version.teacherNotes,
      ));
    }
    
    return ExamGenerationResult(
      versions: updatedVersions,
      summaryForTeacher: result.summaryForTeacher,
      checks: result.checks,
    );
  }

  /// B) Auto-grade a submission
  Future<ExamGrade> gradeSubmission({
    required Exam exam,
    required ExamSubmission submission,
  }) async {
    if (TEST_LAB_MODE) {
      return ExamGrade(
        score: exam.maxScore,
        maxScore: exam.maxScore,
        confidence: 0.95,
        perQuestion: exam.questions.map((q) => QuestionGrade(
          qid: q.qid,
          earned: q.points,
          max: q.points,
          status: GradeStatus.correct,
          hint: 'Great job!',
          topicTag: 'General',
        )).toList(),
        flags: [],
        parentFeedback: ParentFeedback(
          summary: 'Mükemmel bir sınavdı. Konuyu tamamen kavramış görünüyor. (Test Lab Mock)',
          strengths: ['Her şey'],
          improvements: [],
          hintsWithoutSolutions: [],
        ),
      );
    }

    final prompt = ExamAIPrompts.buildGradingPrompt(
      exam: exam,
      submission: submission,
    );

    final response = await _callGemini(prompt);
    final gradeData = response['grade'] as Map<String, dynamic>;
    final feedbackData = response['feedbackToParent'] as Map<String, dynamic>;

    return ExamGrade(
      score: gradeData['score'] as int,
      maxScore: gradeData['maxScore'] as int,
      confidence: (gradeData['confidence'] as num).toDouble(),
      perQuestion: (gradeData['perQuestion'] as List)
          .map((e) => QuestionGrade.fromJson(e as Map<String, dynamic>))
          .toList(),
      flags: (response['flags'] as List).cast<String>(),
      parentFeedback: ParentFeedback.fromJson(feedbackData),
    );
  }

  /// C) Generate parent feedback separately (optional - can be embedded in grading)
  Future<ParentFeedback> generateParentFeedback({
    required Exam exam,
    required int score,
    required int maxScore,
    required String gradeBand,
  }) async {
    final prompt = ExamAIPrompts.buildParentFeedbackPrompt(
      exam: exam,
      score: score,
      maxScore: maxScore,
      gradeBand: gradeBand,
    );

    final response = await _callGemini(prompt);
    return ParentFeedback.fromJson(response);
  }

  /// D) Analyze common errors for a specific question
  Future<List<String>> analyzeCommonErrors({
    required List<ExamSubmission> submissions,
    required String questionId,
    required String questionPrompt,
  }) async {
    final prompt = ExamAIPrompts.buildCommonErrorsPrompt(
      submissions: submissions,
      questionId: questionId,
      questionPrompt: questionPrompt,
    );

    final response = await _callGemini(prompt);
    return (response['commonErrors'] as List).cast<String>();
  }

  /// E) Generate weekly insights
  Future<Map<String, dynamic>> generateWeeklyInsights({
    required String classId,
    required DateTime weekStart,
    required DateTime weekEnd,
    required int examCount,
    required double avgScore,
  }) async {
    final prompt = ExamAIPrompts.buildWeeklyInsightsPrompt(
      classId: classId,
      weekStart: weekStart,
      weekEnd: weekEnd,
      examCount: examCount,
      avgScore: avgScore,
    );

    final response = await _callGemini(prompt);
    return response;
  }

  /// F) Generate class-wide insights for a specific exam
  Future<AIInsights> generateClassInsights({
    required Exam exam,
    required double averageScore,
    required List<QuestionAnalysis> questionBreakdown,
  }) async {
    if (TEST_LAB_MODE) {
      return AIInsights(
        summary: 'Sınıf genelinde ${exam.title} sınavı başarısı yüksek (%${(averageScore/exam.maxScore*100).toInt()}). Özellikle görsel sorular çok iyi anlaşılmış.',
        keyMisconceptions: ['Renk karışımları konusunda bazı öğrencilerde kafa karışıklığı var.', 'Sıralama sorularında acele edilmiş.'],
        successfulTopics: ['Ana Renkler', 'Şekil Eşleştirme', 'Basit Sayma'],
        recommendationsForTeacher: [
          'Ara renkler konusunu bir kez daha pratik aktivitelerle tekrar edebilirsiniz.',
          'Sıralama oyunları ile dikkat süresini artırıcı egzersizler yapılabilir.',
          'Başarılı öğrencilere daha zorlayıcı ek aktiviteler verilebilir.'
        ],
      );
    }

    // TODO: Implement real prompt builder for class insights
    /*
    final prompt = ExamAIPrompts.buildClassInsightsPrompt(
      exam: exam,
      averageScore: averageScore,
      questionBreakdown: questionBreakdown,
    );
    final response = await _callGemini(prompt);
    return AIInsights.fromJson(response);
    */

    // Fallback for now until Prompt is implemented
    return AIInsights(
      summary: 'Analiz tamamlandı. Sınıf ortalaması: $averageScore',
      keyMisconceptions: [],
      successfulTopics: [],
      recommendationsForTeacher: [],
    );
  }

  // ==================== GEMINI API CALL ====================

  Future<Map<String, dynamic>> _callGemini(String prompt) async {
    // Using gemini-2.5-flash (latest stable)
    final url = Uri.parse('$_baseUrl/$_model?key=$_apiKey');
    
    final body = jsonEncode({
      'contents': [
        {
          'parts': [
            {'text': prompt}
          ]
        }
      ],
      'generationConfig': {
        'temperature': 0.7,
        'maxOutputTokens': 8192, // Increased for exam generation
        'topP': 0.95,
      }
    });

    final response = await http.post(
      url,
      headers: {'Content-Type': 'application/json'},
      body: body,
    );

    if (response.statusCode != 200) {
      throw Exception('Gemini API error: ${response.statusCode} - ${response.body}');
    }

    final data = jsonDecode(response.body) as Map<String, dynamic>;
    final candidates = data['candidates'] as List;
    if (candidates.isEmpty) {
      throw Exception('No candidates in Gemini response');
    }

    final content = candidates[0]['content'] as Map<String, dynamic>;
    final parts = content['parts'] as List;
    final text = parts[0]['text'] as String;

    // Parse JSON from response (handle markdown code blocks)
    final jsonMatch = RegExp(r'\{[\s\S]*\}').firstMatch(text);
    if (jsonMatch == null) {
      throw Exception('No JSON in Gemini response: $text');
    }

    return jsonDecode(jsonMatch.group(0)!) as Map<String, dynamic>;
  }
}
